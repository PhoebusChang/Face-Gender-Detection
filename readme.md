# Face Gender Detection with CNN Visualization

A PyTorch Lightning implementation of a Convolutional Neural Network for face gender classification with real-time feature map and filter visualization during training.

## ğŸ¯ Project Overview

This project implements a deep learning solution for binary gender classification from facial images using a custom CNN architecture. The model includes comprehensive visualization tools to understand what the network learns at each convolutional layer during training.

## ğŸ—ï¸ Architecture

### Model Structure
- **Input**: 512Ã—512 RGB face images
- **Conv Layer 1**: 32 filters, 7Ã—7 kernel, stride=2 (512â†’256)
- **Conv Layer 2**: 64 filters, 5Ã—5 kernel, stride=2 (256â†’128) 
- **Conv Layer 3**: 128 filters, 3Ã—3 kernel, stride=2 (128â†’64)
- **MaxPool**: 2Ã—2, stride=2 (64â†’32)
- **Fully Connected**: 128Ã—32Ã—32 â†’ 256 â†’ 2 classes
- **Output**: Binary classification (Male/Female)

### Key Features
- **BatchNormalization** after each conv layer for stable training
- **ReLU activation** functions
- **Dropout (0.5)** for regularization
- **Adam optimizer** with StepLR scheduler
- **Real-time visualization** of feature maps and learned filters

## ğŸ“Š Visualization Features

The project includes comprehensive visualization tools that generate images during training:

### Feature Maps Visualization
Shows how the network processes images at each layer:
- **Original images** (denormalized for display)
- **Conv1 feature maps**: Early edge and texture detection
- **Conv2 feature maps**: Facial pattern recognition  
- **Conv3 feature maps**: High-level gender-specific features
- **Average feature maps**: Combined channel representations

### Filter Visualization
Displays the actual learned kernels/weights:
- **Conv1 filters**: Low-level feature detectors (edges, textures)
- **Conv2 filters**: Mid-level pattern detectors
- **Conv3 filters**: High-level feature detectors

![Feature Maps Example](visuals/epoch_0.png)
*Example: Feature maps and filters visualization at epoch 0*

![Filters Only](visuals/epoch_0_filters.png)
*Example: Learned filters visualization showing what each layer detects*

## ğŸš€ Getting Started

### Prerequisites
```bash
pip install torch torchvision pytorch-lightning matplotlib pillow
```

### Dataset Structure
```
datasets/
â””â”€â”€ ashwingupta3012/
    â””â”€â”€ male-and-female-faces-dataset/
        â””â”€â”€ versions/1/
            â””â”€â”€ Male and Female face dataset/
                â”œâ”€â”€ male/
                â”‚   â”œâ”€â”€ image1.jpg
                â”‚   â””â”€â”€ ...
                â””â”€â”€ female/
                    â”œâ”€â”€ image1.jpg
                    â””â”€â”€ ...
```

### Training with Visualization
```bash
python main_visualize.py
```

### Inference Only
```bash
python main.py
```

## ğŸ“ File Structure

```
Face-Gender-Detection/
â”œâ”€â”€ main.py                    # Main training and inference script
â”œâ”€â”€ main_visualize.py         # Training with visualization features
â”œâ”€â”€ visuals/                  # Generated visualization images
â”‚   â”œâ”€â”€ epoch_0.png          # Feature maps per epoch
â”‚   â”œâ”€â”€ epoch_0_filters.png  # Filter visualizations
â”‚   â””â”€â”€ ...
â”œâ”€â”€ model.pth                 # Saved model weights
â”œâ”€â”€ test.png                  # Test image for inference
â””â”€â”€ README.md
```

## ğŸ”§ Configuration

### Data Preprocessing
```python
transforms = transforms.Compose([
    transforms.Resize((512, 512)),           # Resize to fixed dimensions
    transforms.ToTensor(),                   # Convert to tensor
    transforms.Normalize((0.5, 0.5, 0.5),   # Normalize to [-1, 1]
                        (0.5, 0.5, 0.5))
])
```

### Training Parameters
- **Batch Size**: 32
- **Learning Rate**: 0.001 (Adam optimizer)
- **Scheduler**: StepLR (decay by 0.1 every 10 epochs)
- **Max Epochs**: 10
- **Train/Val Split**: 80/20

## ğŸ“ˆ Model Performance

The model tracks training and validation loss with PyTorch Lightning's built-in logging:
- Real-time loss visualization in progress bars
- Automatic GPU/CPU device selection
- Mixed precision training support

## ğŸ¨ Visualization Details

### Feature Map Interpretation
- **Bright areas (yellow)**: High activation regions
- **Dark areas (purple)**: Low activation regions
- **Progressive abstraction**: Conv1â†’Conv2â†’Conv3 shows increasing feature complexity

### Filter Interpretation
- **Red regions**: Positive weights
- **Blue regions**: Negative weights
- **Filter evolution**: Shows how kernels adapt during training

## ğŸ” Usage Examples

### Training
```python
# Training with visualization
python main_visualize.py
```

### Inference
```python
# Place your test image as 'test.png' and run:
python main.py
# Follow prompts to classify images
```

### Expected Output
```
Predicted: female
Confidence: 87.34%
Probabilities: Female: 87.34%, Male: 12.66%
```

## ğŸ› ï¸ Customization

### Modify Architecture
Edit the `imageCNN` class in `main_visualize.py`:
```python
# Change filter counts
self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3)  # More filters

# Adjust learning rate
optimizer = optim.Adam(self.parameters(), lr=0.0001)  # Lower LR
```

### Visualization Frequency
```python
# Visualize every N epochs
if self.current_epoch % 5 == 0:  # Every 5 epochs instead of every epoch
    self.visualize_features()
```

## ğŸ“‹ Technical Details

### Memory Optimization
- **Gradient detachment** for visualization tensors
- **Automatic mixed precision** support
- **Efficient data loading** with DataLoader

### Normalization Strategy
- Input normalization to [-1, 1] range
- BatchNorm after each convolution
- Proper denormalization for visualization

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add visualizations if applicable
5. Submit a pull request

## ğŸ“ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- Dataset: Male and Female Faces Dataset
- Framework: PyTorch Lightning
- Visualization: Matplotlib

---

**Note**: Ensure the `visuals/` directory exists before training to save visualization images.